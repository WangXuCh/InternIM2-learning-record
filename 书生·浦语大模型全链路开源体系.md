### 书生·浦语大模型全链路开源体系

2023.06.07 -> InternLM千亿参数语言大模型发布

2023.07.06 ->  InternLM千亿参数语言大模型全面升级，支持8K语境、26种语言。全面开源、免费商用：InternLM-7B、全链条开源工具体系

2023.08.14 -> 书生·万卷1.0多模态预训练语料库开源发布

2023.08.21 -> 升级版对话模型InternLM-Chat-7B v1.1发布，开源智能体框架Lagent，支持从语言模型到智能体升级转换

2023.08.28 ->  InternLM 千亿参数模型的参数两升级到123B

2023.09.20 ->  增强版InternLM-20B开源，开源工具链全线升级



#### 书生·浦语2.0（InternLM2）的体系

![image-20240329095401075](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20240329095401075.png)

#### 主要亮点：

1. 在超长的上下文token中表现比较好
2. 推理、数学、代码提升比较显著，Chat-20B模型的能力比肩ChatGPT
3. 对话和创作体验超越GPT-3.5和Gemini Pro
4. 可以实现复杂的智能体搭建
5. 数理分析能力和数据分析能力与GPT4不相上下



#### 模型应用的流程：

![image-20240329095526663](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20240329095526663.png)

#### 高质量预料数据

![image-20240329095551469](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20240329095551469.png)

#### 预训练技术：

- 支持多卡训练
- 速度提升50%，多种并行策略

![image-20240329095608107](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20240329095608107.png)

#### 微调：

- 增量续训：主要是想保证模型原本的知识，并让它能学到一些新的知识
- 有监督微调：比如模型有一个特定的使用场景，则可以利用该场景的数据对模型进行微调，让模型在该场景表现更好
- 全量参数微调：模型所有的参数都会得到训练
- 部分参数微调：只训练模型的一部分参数



#### 高效微调框架XTuner：

![image-20240330160702089](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20240330160702089.png)



#### 评测：

2023.05.01 -> 完成Alpha版本的该法，支持千亿参数语言大模型高效评测

2023.07.06 ->  OpenCompass正式开源，支持五大能力维度，70个数据集，40万评测题目

2023.08.18 ->  OpenCompass数据和性能对比上线，支持100+开源模型的多维度性能对比

2023.09.07 -> 支持多编程语言代码评测，发布稳定可复现的代码评测镜像，提供多编程语言能力分析和对比

2023.10.26 ->  联合南京大学推出大模型司法能力评测基准，构建多层能力体系主力法律场景能力分析（相当于私域大模型开发）

2023.12.01 ->  发布多模态评测工具套件VLMEvalKit，支持包括Femini、GPT-4V等商业模型评测支持

2024.01.30 -> OpenCompass2.0思南大模型评测体系正式发布

CompassKit：大模型评测全栈工具链

- 提供多种数据污染监测方法，支持包括GSM-8K、MMLU等主流数据集上的污染检测
- 丰富的模型推理接入，支持20个商业模型API，支持LMDeploy、vLLM、LighLLM等推理后端
- 支持200Ktoken测试，支持多个主流长文本评测基准
- 支持基于大模型评价的主观测评
- 提供模型打分、模型对战多种能力，灵活切换上百种评价模型



通过OpenCompass年度榜单来看：各类模型的整体能力仍有较大的提升空间，比如GPT-4-Turbo也仅仅达到了61.8的及格分；复杂推理任然是短板；模型对数学、推理、代码等的性能和尺寸呈现较强相关性；模型的主观性能和客观性能存在较大偏差



#### 部署：

LMDeploy提供大模型在GPU上部署的全流程解决方案，包括模型轻量化、推理和服务

![image-20240330165907236](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20240330165907236.png)

优势：

- 高效推理引擎：持续批处理技巧、熟读优化的低比特计算kernels、模型并行、高效的k/v缓存管理机制
- 完备易用的工具链：量化、推理、服务全流程，无缝对接OpenCompass评测推理精度，多维度推理速度评测工具
- 支持交互式推理



#### 智能体：

![image-20240330170009708](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20240330170009708.png)



多模态智能体工具箱AgentLego的特点：

- 丰富的工具集合，提供了大量视觉、多模态相关领域的前沿算法功能
- 支持多个主流智能体系统，如LangChain、Transformers Agent、lagent等
- 灵活的多模态工具调用接口，可以轻松支持各类输入输出格式的工具函数
- 一键式远程工具部署，轻松使用和调试大模型智能体

