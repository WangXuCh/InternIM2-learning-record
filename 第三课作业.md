# 第三课作业

## 基础作业

#### 1. 在[茴香豆 Web 版](https://openxlab.org.cn/apps/detail/tpoisonooo/huixiangdou-web)中创建自己领域的知识问答助手

- 创建自己的数据，我创建了一个亮剑主人公李云龙的数据

  ![image-20240411182802398](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240411182802398.png)

- 设置正反例让茴香豆可以更好的回复信息或者避免回复和相关领域无关信息

  ![image-20240411183414028](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240411183414028.png)

  ![image-20240411183420382](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240411183420382.png)

- 开始尝试聊天

​	问题一：李云龙是谁？

![image-20240411183536082](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240411183536082.png)

​	问题二：他参加过哪些战争？

![image-20240411183613339](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240411183613339.png)

​	问题三：他都担任过什么职务？（敏感问题，无法显示。。。。。）

![image-20240411183910264](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240411183910264.png)

​	问题四：李云龙是怎么参加八路军的？

![image-20240411184036683](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240411184036683.png)

​	问题五：尝试加入反例：今天晚上吃什么？

![image-20240411184137988](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240411184137988.png)

可以看出，茴香豆并没有给出回应，说明它意识到这是个需要拒答的问题。



总结：从网上找了一些关于李云龙的资料，上传到了茴香豆web端，实现了对李云龙这个角色的分析，同时设置了一些拒答问题，它能够正确识别这些问题，并不做回应。就我个人而言，我感觉这个确实很方便，完全不需要单独进行训练或微调它就能回答一些专有的问题，这给普通人带来了极大的遍历。以后可以给自己的微信群弄几个小助手！



#### 2.在 `InternLM Studio` 上部署茴香豆技术助手

1. 修改配置文件。用已下载模型的路径替换 `/root/huixiangdou/config.ini` 文件中的默认模型，需要修改 3 处模型地址，分别是:

- ​	命令行输入下面的命令，修改用于向量数据库和词嵌入的模型

  ```
  sed -i '6s#.*#embedding_model_path = "/root/models/bce-embedding-base_v1"#' /root/huixiangdou/config.ini
  ```

- ​	用于检索的重排序模型

  ```
  sed -i '7s#.*#reranker_model_path = "/root/models/bce-reranker-base_v1"#' /root/huixiangdou/config.ini
  ```

- ​	和本次选用的大模型

  ```
  sed -i '29s#.*#local_llm_path = "/root/models/internlm2-chat-7b"#' /root/huixiangdou/config.ini
  ```

​	修改完成后如下图所示：

![image-20240407103955749](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240407103955749.png)

2. 创建知识库

   本示例中，使用 **InternLM** 的 **Huixiangdou** 文档作为新增知识数据检索来源，在不重新训练的情况下，打造一个 **Huixiangdou** 技术问答助手。

   首先，下载 **Huixiangdou** 语料：

   ```
   cd /root/huixiangdou && mkdir repodir
   git clone https://github.com/internlm/huixiangdou --depth=1 repodir/huixiangdou
   ```

   ![image-20240407104549705](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240407104549705.png)

   提取知识库特征，创建向量数据库。数据库向量化的过程应用到了 **LangChain** 的相关模块，默认嵌入和重排序模型调用的网易 **BCE 双语模型**，如果没有在 `config.ini` 文件中指定本地模型路径，茴香豆将自动从 **HuggingFace** 拉取默认模型。

   除了语料知识的向量数据库，茴香豆建立接受和拒答两个向量数据库，用来在检索的过程中更加精确的判断提问的相关性，这两个数据库的来源分别是：

   - 接受问题列表，希望茴香豆助手回答的示例问题
     - 存储在 `huixiangdou/resource/good_questions.json` 中
   - 拒绝问题列表，希望茴香豆助手拒答的示例问题
     - 存储在 `huixiangdou/resource/bad_questions.json` 中
     - 其中多为技术无关的主题或闲聊
     - 如："nihui 是谁", "具体在哪些位置进行修改？", "你是谁？", "1+1"

​		运行下面的命令，增加茴香豆相关的问题到接受问题示例中：

```
cd /root/huixiangdou
mv resource/good_questions.json resource/good_questions_bk.json

echo '[
    "mmpose中怎么调用mmyolo接口",
    "mmpose实现姿态估计后怎么实现行为识别",
    "mmpose执行提取关键点命令不是分为两步吗，一步是目标检测，另一步是关键点提取，我现在目标检测这部分的代码是demo/topdown_demo_with_mmdet.py demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth   现在我想把这个mmdet的checkpoints换位yolo的，那么应该怎么操作",
    "在mmdetection中，如何同时加载两个数据集，两个dataloader",
    "如何将mmdetection2.28.2的retinanet配置文件改为单尺度的呢？",
    "1.MMPose_Tutorial.ipynb、inferencer_demo.py、image_demo.py、bottomup_demo.py、body3d_pose_lifter_demo.py这几个文件和topdown_demo_with_mmdet.py的区别是什么，\n2.我如果要使用mmdet是不是就只能使用topdown_demo_with_mmdet.py文件，",
    "mmpose 测试 map 一直是 0 怎么办？",
    "如何使用mmpose检测人体关键点？",
    "我使用的数据集是labelme标注的，我想知道mmpose的数据集都是什么样式的，全都是单目标的数据集标注，还是里边也有多目标然后进行标注",
    "如何生成openmmpose的c++推理脚本",
    "mmpose",
    "mmpose的目标检测阶段调用的模型，一定要是demo文件夹下的文件吗，有没有其他路径下的文件",
    "mmpose可以实现行为识别吗，如果要实现的话应该怎么做",
    "我在mmyolo的v0.6.0 (15/8/2023)更新日志里看到了他新增了支持基于 MMPose 的 YOLOX-Pose，我现在是不是只需要在mmpose/project/yolox-Pose内做出一些设置就可以，换掉demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py 改用mmyolo来进行目标检测了",
    "mac m1从源码安装的mmpose是x86_64的",
    "想请教一下mmpose有没有提供可以读取外接摄像头，做3d姿态并达到实时的项目呀？",
    "huixiangdou 是什么？",
    "使用科研仪器需要注意什么？",
    "huixiangdou 是什么？",
    "茴香豆 是什么？",
    "茴香豆 能部署到微信吗？",
    "茴香豆 怎么应用到飞书",
    "茴香豆 能部署到微信群吗？",
    "茴香豆 怎么应用到飞书群",
    "huixiangdou 能部署到微信吗？",
    "huixiangdou 怎么应用到飞书",
    "huixiangdou 能部署到微信群吗？",
    "huixiangdou 怎么应用到飞书群",
    "huixiangdou",
    "茴香豆",
    "茴香豆 有哪些应用场景",
    "huixiangdou 有什么用",
    "huixiangdou 的优势有哪些？",
    "茴香豆 已经应用的场景",
    "huixiangdou 已经应用的场景",
    "huixiangdou 怎么安装",
    "茴香豆 怎么安装",
    "茴香豆 最新版本是什么",
    "茴香豆 支持哪些大模型",
    "茴香豆 支持哪些通讯软件",
    "config.ini 文件怎么配置",
    "remote_llm_model 可以填哪些模型?"
]' > /root/huixiangdou/resource/good_questions.json
```

![image-20240407104626077](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240407104626077.png)		

​		再创建一个测试用的问询列表，用来测试拒答流程是否起效：

```
cd /root/huixiangdou

echo '[
"huixiangdou 是什么？",
"你好，介绍下自己"
]' > ./test_queries.json
```

​		![image-20240407104653926](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240407104653926.png)

​		在确定好语料来源后，运行下面的命令，创建 RAG 检索过程中使用的向量数据库：

```
# 创建向量数据库存储目录
cd /root/huixiangdou && mkdir workdir 

# 分别向量化知识语料、接受问题和拒绝问题中后保存到 workdir
python3 -m huixiangdou.service.feature_store --sample ./test_queries.json
```

​		向量数据库的创建需要等待一小段时间，过程约占用 1.6G 显存。

![image-20240407112054201](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240407112054201.png)

​		完成后，**Huixiangdou** 相关的新增知识就以向量数据库的形式存储在 `workdir` 文件夹下。

​		检索过程中，茴香豆会将输入问题与两个列表中的问题在向量空间进行相似性比较，判断该问题是否应该回答，避免群聊过程中的问答泛滥。确定的回答的问题会利用基础模型提取关键词，在知识库中检索 `top K` 相似的 `chunk`，综合问题和检索到的 `chunk` 生成答案。

![image-20240407112127367](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240407112127367.png)

3. 运行茴香豆知识助手

   ```
   # 填入问题
   sed -i '74s/.*/    queries = ["huixiangdou 是什么？", "茴香豆怎么部署到微信群", "今天天气怎么样？"]/' /root/huixiangdou/huixiangdou/main.py
   
   # 运行茴香豆
   cd /root/huixiangdou/
   python3 -m huixiangdou.main --standalone
   ```

   RAG 技术的优势就是非参数化的模型调优，这里使用的仍然是基础模型 `InternLM2-Chat-7B`， 没有任何额外数据的训练。面对同样的问题，我们的**茴香豆技术助理**能够根据我们提供的数据库生成准确的答案：

![image-20240407112612425](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240407112612425.png)

![image-20240407112622986](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240407112622986.png)

web版的部署尝试了很多次，均没有运行成功，过程截图如下：

![3462d66ff4ef37aecc5faa477662ed8](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/3462d66ff4ef37aecc5faa477662ed8.png)

![4db930630d1cbd7986bcc9dbf98ae11](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/4db930630d1cbd7986bcc9dbf98ae11.png)

总结：在Studio上部署茴香豆技术助手还是需要一点能力去处理遇到的bug的。这部分相对于第一部分来说，操作稍微有点麻烦，不过最后的结果还是好的，毕竟大家都是要从源码入手的，而不是一个简单的web-demo。
<<<<<<< HEAD





## 进阶作业：部署到飞书

参考链接：[‍⁢⁣⁤⁡⁢⁡⁣⁡⁣⁣‍‌﻿⁢‍﻿‍⁡⁡‬⁡⁣⁢‍﻿‬⁢‬‍⁡⁣⁤‌⁢⁤⁡‬‬⁣⁣⁣茴香豆零编程接入飞书 - 飞书云文档 (feishu.cn)](https://aicarrier.feishu.cn/docx/H1AddcFCioR1DaxJklWcLxTDnEc)

- 首先进入[飞书开放平台](https://open.feishu.cn/app?lang=zh-CN)，创建企业自建应用

  ![image-20240412085328209](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240412085328209.png)

- 点击添加一个机器人

  ![image-20240412085349900](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240412085349900.png)

- 复制基础信息-凭证与基础信息tab下，应用凭证中 App ID和App Secret，填入到 Integrate With Lark 的表单中

  ![image-20240412085449887](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240412085449887.png)

  ![image-20240412085523325](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240412085523325.png)

- 复制茴香豆Web中你的知识库下，Integrate With Lark 中提供的加密策略，填入到开发配置-事件与回调tab下的加密策略，注意两项都需要填入

  ![image-20240412085620160](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240412085620160.png)

  ![image-20240412085651036](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240412085651036.png)

- 复制茴香豆Web中你的知识库下，Integrate With Lark 中提供的事件回调地址，填入到开发配置-事件与回调tab下的事件配置，选择默认的【将事件发送至开发者服务器】即可，点击保存后若修改成功，则表示鉴权成功。

  ![image-20240412085727089](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240412085727089.png)

  ![image-20240412085746328](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240412085746328.png)

- 订阅事件：继续点击当前页面的【添加事件】按钮，搜索【接收消息】事件，并申请开通对应权限

  ![image-20240412085834481](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240412085834481.png)

- 权限配置：点击开发配置-权限管理tab下，申请开通权限：im:chat:readonly 和 im:message:send_as_bot

  ![image-20240412085915860](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240412085915860.png)

- 点击上方提示栏，发布当前应用版本，提示“已发布”后即配置成功。

- 将刚刚创建并发布的应用机器人添加到群聊中，参考[在群组中使用机器人](https://www.feishu.cn/hc/zh-CN/articles/360024984973-在群组中使用机器人)

- 复制茴香豆Web中你的知识库下，Integrate With Lark 中提供的suffix字符串，在飞书群名称后直接添加该suffix

### 在飞书群聊中添加完机器人的测试图

![image-20240412084630564](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240412084630564.png)

可以看出没有修改群名后缀的时候机器人并不能对问题做出反应。

![image-20240412085100781](https://github.com/WangXuCh/InternIM2-learning-record/blob/main/typora-user-images/image-20240412085100781.png)

修改后缀后，如果还无法与机器人互动，则移除机器人并重新加入一个机器人即可。
